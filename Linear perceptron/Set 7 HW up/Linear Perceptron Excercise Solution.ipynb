{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwxWcO7fqb-L"
   },
   "source": [
    "# Excercise - Multi-class classification of MNIST using Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcygblmOmQDZ"
   },
   "source": [
    "In binary perceptron, where $\\mathbf{y} \\in \\{-1, +1\\}$, we used to update our weights only for wrongly classified examples.\n",
    "\n",
    "The multi-class perceptron is regarded as a generalization of binary perceptron. Learning through iteration is the same as the perceptron. Weighted inputs are passed through a multiclass signum activation function. If the predicted output label is the same as true label then weights are not updated. However, when predicted output label $\\neq$ true label, then the wrongly classified input example is added to the weights of the correct label and subtracted from the weights of the incorrect label. Effectively, this amounts to ’rewarding’ the correct weight vector, ’punishing’ the misleading, incorrect weight\n",
    "vector, and leaving alone an other weight vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "import math\n",
    "import gif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223975,
     "status": "ok",
     "timestamp": 1596984132348,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "gNkGLnbjTY-s"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(11)\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "def one_hot(a):\n",
    "  b = -1 * np.ones((a.size, a.max()+1))\n",
    "  b[np.arange(a.size), a] = 1\n",
    "  return b\n",
    "\n",
    "# Loading digits datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "X = digits.data\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223957,
     "status": "ok",
     "timestamp": 1596984132353,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "0BPvc5P8KvrM",
    "outputId": "233f09b1-7641-4c60-c21d-74a2264f8bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1257, 65)\n",
      "Validation dataset:  (180, 65)\n",
      "Test dataset:  (360, 65)\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test data\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223939,
     "status": "ok",
     "timestamp": 1596984132358,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "QPJZdeDtUfoy",
    "outputId": "66a50417-5c21-4158-f029-20ef755e50f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig();\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2KVp57S1Zah"
   },
   "source": [
    "#### Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2874,
     "status": "ok",
     "timestamp": 1596983910402,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "05nyKS2TBZJC",
    "outputId": "fdd07951-2d3f-484a-a790-d6e08331baa0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running importer\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        #print('searching: %s'%nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        #print('searching: %s' % nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        #print('Found %d cells'%len(nb.cells))\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "\n",
    "#  register the NotebookFinder with sys.meta_path\n",
    "print('running importer')\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14073,
     "status": "ok",
     "timestamp": 1596983921673,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "OmcZvOJHJ0Qp",
    "outputId": "30aedb40-abdf-4f3b-efba-20dc33fbd835"
   },
   "outputs": [],
   "source": [
    "# Import all relevant functions\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import plot_decision_boundary, multi_class_signum, get_accuracy, get_prediction\n",
    "from utils import plot_2D_input_datapoints, generate_gifs, normalize, signum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "import math\n",
    "import gif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has stabilized with all points classified:  216\n",
      "Training completed at 10000 epochs. 15 misclassified points remain.\n",
      "Training has stabilized with all points classified:  102\n",
      "Training has stabilized with all points classified:  1377\n",
      "Training has stabilized with all points classified:  235\n",
      "Training has stabilized with all points classified:  416\n",
      "Training has stabilized with all points classified:  330\n",
      "Training has stabilized with all points classified:  312\n",
      "Training completed at 10000 epochs. 57 misclassified points remain.\n",
      "Training completed at 10000 epochs. 8 misclassified points remain.\n"
     ]
    }
   ],
   "source": [
    "# Perceptron training algorithm\n",
    "def train(X_train, Y_train,weights, learning_rate=1, total_epochs=100):\n",
    "\n",
    "  \"\"\"Training method for Perceptron.\n",
    "  \n",
    "  Parameters\n",
    "  -----------\n",
    "\n",
    "  X_train: ndarray (num_examples(rows) vs num_features(columns))\n",
    "    Input dataset which perceptron will use to learn optimal weights\n",
    "  \n",
    "  Y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "    Class labels for input data\n",
    "\n",
    "  weights: ndarray (num_features vs n_output)\n",
    "    Weights used to train the network and predict on test set\n",
    "\n",
    "  learning_rate: int\n",
    "    Learning rate use to learn and update weights\n",
    "  \n",
    "  total_epochs: int\n",
    "    Max number of epochs to train the perceptron model\n",
    "  \"\"\"\n",
    "\n",
    "  n_samples, _ = np.shape(X_train)\n",
    "   \n",
    "  history_weights = []\n",
    "  epoch = 1\n",
    "\n",
    "  # Number of missclassified points we would like to see in the train set.\n",
    "  # While training, its value will change every epoch. If m==0, our training \n",
    "  # error will be zero.\n",
    "  m = 1\n",
    "\n",
    "  # If the most recent weights gave 0 misclassifications, break the loop.\n",
    "  # Else continue until total_epochs is completed.\n",
    "  while m != 0 and epoch <= total_epochs:\n",
    "    m = 0\n",
    "\n",
    "    # Compute weighted inputs and predict class labels on training set.\n",
    "    weights_transpose_x = np.dot(X_train, weights)\n",
    "    weights_transpose_x = signum(weights_transpose_x)\n",
    "    y_train_out = np.multiply(Y_train, weights_transpose_x)\n",
    "    epoch += 1\n",
    "    \n",
    "    #print(\"computed weights\", weights_transpose_x.shape , y_train_out.shape)\n",
    "    \n",
    "    # Collecting misclassified indexes and count them\n",
    "    y_miscls_idxs = np.argwhere(y_train_out <= 0)[:, 0]\n",
    "    y_miscls_idxs = np.unique(y_miscls_idxs)\n",
    "    m = len(y_miscls_idxs)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    dweights = np.dot((X_train[y_miscls_idxs]).T, Y_train[y_miscls_idxs])\n",
    "    \n",
    "    #print(\"gradients step \", dweights.shape , weights.shape)\n",
    "    #weights = weights.reshape((-1,)) \n",
    "    #print(\"gradients step \", dweights.shape , weights.shape)\n",
    "    weights += (learning_rate/n_samples) * dweights\n",
    "    weights = np.round(weights, decimals=4)\n",
    "\n",
    "    # Append weights to visualize decision boundary later\n",
    "    history_weights.append(weights)\n",
    "\n",
    "  if m == 0 and epoch <= total_epochs:\n",
    "    print(\"Training has stabilized with all points classified: \", epoch)\n",
    "  else:\n",
    "    print(f'Training completed at {epoch-1} epochs. {m} misclassified points remain.')\n",
    "\n",
    "  return history_weights[-1], m \n",
    "\n",
    "# Run each \n",
    "weights = np.zeros((X_train.shape[1],Y_train.shape[1])) \n",
    "for i in range(Y_train.shape[1]):\n",
    "    w,err = train(X_train, Y_train[:,i],weights[:,i], learning_rate=0.05, total_epochs=10000)   \n",
    "    weights[:,i] = w                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation = 94.44444444444444 vs test performance = 95.83333333333334 \n"
     ]
    }
   ],
   "source": [
    "val_acc , val_pred = get_prediction(X_val,Y_val,weights, get_acc=True, model_type='perceptron', predict='no')\n",
    "test_acc , test_pred = get_prediction(X_test,Y_test,weights, get_acc=True, model_type='perceptron', predict='no')\n",
    "\n",
    "result = f\"validation performance = {val_acc} vs test performance = {test_acc}\"\n",
    "print(result )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the number of epoches the miscalassification rate drop significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZQQfFFOrqST3"
   ],
   "name": "LinearPerceptron_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
