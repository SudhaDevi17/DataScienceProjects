{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1\n",
    "\n",
    "In the tutorial you saw how to compute LDA for a two class problem. In this excercise we will work on a multi-class problem. We will be working with the famous Iris dataset that has been deposited on the UCI machine learning repository\n",
    "(https://archive.ics.uci.edu/ml/datasets/Iris).\n",
    "\n",
    "The iris dataset contains measurements for 150 iris flowers from three different species.\n",
    "\n",
    "The three classes in the Iris dataset:\n",
    "1. Iris-setosa (n=50)\n",
    "2. Iris-versicolor (n=50)\n",
    "3. Iris-virginica (n=50)\n",
    "\n",
    "The four features of the Iris dataset:\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "\n",
    "<img src=\"iris_petal_sepal.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import pi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width           Class\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Once dataset is loaded into a pandas data frame object, the first step is to divide dataset into features and corresponding labels and then divide the resultant dataset into training and test sets. The following code divides data into labels and feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script assigns the first four columns of the dataset i.e. the feature set to X variable while the values in the fifth column (labels) are assigned to the y variable.\n",
    "\n",
    "The following code divides data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "\n",
    "We will now perform feature scaling as part of data preprocessing too. For this task, we will be using scikit learn `StandardScalar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your code below\n",
    "\n",
    "Write you code below to LDA on the IRIS dataset and compute the overall accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE ####\n",
    "# Calculating covariance of an input matrix\n",
    "def calc_cov_matrix(X_input):\n",
    "  n_samples = np.shape(X_input)[0]\n",
    "  cov_matrix = np.array((1 / (n_samples-1)) * (X_input - X_input.mean(axis=0)).T.dot(X_input - X_input.mean(axis=0)))\n",
    "\n",
    "  return cov_matrix\n",
    "def train(X_train, y_train):\n",
    "\n",
    "  \"\"\"Train method for LDA.\n",
    "\n",
    "  Parameters\n",
    "  -----------\n",
    "  X_train: ndarray (num_examples(rows) vs num_features(columns))\n",
    "   Input dataset which LDA will use to obtain optimal weights during training\n",
    "\n",
    "  y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "  \"\"\"\n",
    "  \n",
    "  # Collecting all class 0 and class 1 into separate variables\n",
    "  class_X0 = X_train[np.argwhere(y_train == 0)[:, 0]]\n",
    "  class_X1 = X_train[np.argwhere(y_train == 1)[:, 0]]\n",
    "\n",
    "  # Getting number of examples in each class\n",
    "  num_class_X0_samples = np.shape(class_X0)[0]\n",
    "  num_class_X1_samples = np.shape(class_X1)[0]\n",
    "\n",
    "  # Computing class mean for each label and calculating the difference between them.\n",
    "  class_X0_mean = class_X0.mean(0)\n",
    "  class_X1_mean = class_X1.mean(0)\n",
    "  class_mean_diff = class_X1_mean - class_X0_mean\n",
    "  class_mean_diff = class_mean_diff.reshape((-1, 1))\n",
    "  SB = np.dot(class_mean_diff, class_mean_diff.T)\n",
    "\n",
    "  # Calculating covariance matrix\n",
    "  cov_mat_class_X0 = calc_cov_matrix(class_X0)\n",
    "  cov_mat_class_X1 = calc_cov_matrix(class_X1)\n",
    "  #SW = num_class_X0_samples * cov_mat_class_X0 + num_class_X0_samples * cov_mat_class_X1\n",
    "  SW = cov_mat_class_X0 + cov_mat_class_X1\n",
    "\n",
    "  eigvals, eigvecs = np.linalg.eig(np.linalg.pinv(SW).dot(SB))\n",
    "\n",
    "  # Getting the eigenvectors with the maximum eigenvalue.\n",
    "  idx = eigvals.argsort()[::-1]\n",
    "  eigvals = eigvals[idx][:1]\n",
    "  weights = np.atleast_1d(eigvecs[:, idx])[:, :1]\n",
    "\n",
    "  return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = []\n",
    "n = np.unique(y)\n",
    "\n",
    "for i in n:\n",
    "    if i in y_train:\n",
    "        y_vec = np.where(y_train == i, 1 , 0 ) \n",
    "        trained_weights.append( train(X_train, y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.16705006],\n",
       "        [-0.15448432],\n",
       "        [ 0.97066801],\n",
       "        [ 0.07766913]]),\n",
       " array([[-0.15159054],\n",
       "        [-0.20359827],\n",
       "        [ 0.75831223],\n",
       "        [-0.60044201]]),\n",
       " array([[ 0.06511834],\n",
       "        [-0.16857946],\n",
       "        [-0.2169602 ],\n",
       "        [-0.95930644]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_weights[0], trained_weights[1] , trained_weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(trained_weights)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-virginica'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = np.shape(y_test)[0]\n",
    "y_test_predicted = []\n",
    "for i in range(m):\n",
    "    y_test_predicted.append(np.dot(X_test, trained_weights[i]))\n",
    "#     y_test_predicted[y_test_predicted >= 0] = 1\n",
    "#     y_test_predicted[y_test_predicted < 0] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted[0].reshape((-1,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 , df2, df3 = pd.DataFrame(y_test_predicted[0]) ,pd.DataFrame(y_test_predicted[1]),pd.DataFrame(y_test_predicted[2])\n",
    "df = pd.concat([df1 , df2, df3], axis = 1 )\n",
    "             #, column = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.925654</td>\n",
       "      <td>-0.225588</td>\n",
       "      <td>-1.514096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0     0.925654        -0.225588       -1.514096"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Iris-setosa\n",
       "dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1].apply(lambda x : x.argmax(), axis = 1 )#.loc(0, ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_predictions = df.apply(lambda x: x.argmin(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  56.666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Getting misclassfied points on test set\n",
    "miscls_test_points = np.unique(np.argwhere(y_predictions != y_test)[:, 0])\n",
    "accuracy = 1-(len(miscls_test_points)/num_test_samples)\n",
    "print(\"Accuracy: \", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([pd.DataFrame(y_predictions), pd.DataFrame(y_test)] , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
